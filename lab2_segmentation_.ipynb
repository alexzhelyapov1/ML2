{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxoefJKSbYpd"
      },
      "source": [
        "# Lab 02: Segmentation\n",
        "\n",
        "In this laboratory work you will create pipeline for cancer cells segmentation starting from reading data to preprocessing, creating training setup, experimenting with models.\n",
        "\n",
        "## Part 1: Reading dataset\n",
        "\n",
        "Write Dataset class inheriting regular `torch` dataset.\n",
        "\n",
        "In this task we use small datset just to make this homework accessible for everyone, so please **do not** read all the data in constructor because it is not how it works for real life datasets. You need to read image from disk only when it is requesed (getitem).\n",
        "\n",
        "Split data (persistently between runs) to train, val and test sets. Add corresponding parameter to dataset constructor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjimnlWTWxdz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "if not os.path.exists('breast-cancer-cells-segmentation.zip'):\n",
        "    !curl -JLO 'https://www.dropbox.com/scl/fi/gs3kzp6b8k6faf667m5tt/breast-cancer-cells-segmentation.zip?rlkey=md3mzikpwrvnaluxnhms7r4zn'\n",
        "    !unzip breast-cancer-cells-segmentation.zip\n",
        "else:\n",
        "    print('Dataset is already downloaded')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1.1: Analyzing dataset\n",
        "\n",
        "Each time you build model you first should make EDA to understand your data.\n",
        "\n",
        "You should answer to the following questions:\n",
        "- how many classes do you have?\n",
        "- what is class balance?\n",
        "- how many cells (roughly) do you have in train data?\n",
        "\n",
        "Advanced part: think of questions which could help you in your future models building and then answer them below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buchW2rlaki0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from tqdm.notebook import tqdm\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "IMG_DIR = 'Images'\n",
        "MASK_DIR = 'Masks'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_files_with_type = []\n",
        "image_files = sorted(glob.glob(os.path.join(IMG_DIR, '*_ccd.tif')))\n",
        "mask_files_set = set(sorted(glob.glob(os.path.join(MASK_DIR, '*.TIF'))))\n",
        "\n",
        "for img_path in image_files:\n",
        "    basename = os.path.basename(img_path)\n",
        "    parts = basename.replace('_ccd.tif', '').split('_')\n",
        "    if len(parts) >= 2:\n",
        "        tumor_type = parts[-1]\n",
        "    else:\n",
        "        print(f\"Warning: Could not extract tumor type from {basename}\")\n",
        "        tumor_type = \"unknown\"\n",
        "\n",
        "    mask_basename = basename.replace('_ccd.tif', '.TIF')\n",
        "    expected_mask_path = os.path.join(MASK_DIR, mask_basename)\n",
        "\n",
        "    if expected_mask_path in mask_files_set:\n",
        "        all_files_with_type.append((img_path, expected_mask_path, tumor_type))\n",
        "    else:\n",
        "        print(f\"Warning: Mask not found for image {img_path}\")\n",
        "\n",
        "print(f\"Найдено {len(image_files)} изображений.\")\n",
        "print(f\"Найдено {len(mask_files_set)} масок.\")\n",
        "print(f\"Создано {len(all_files_with_type)} пар изображение/маска с типом опухоли.\")\n",
        "\n",
        "random.seed(42)\n",
        "random.shuffle(all_files_with_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tumor_type_counts = Counter()\n",
        "for _, _, tumor_type in all_files_with_type:\n",
        "    tumor_type_counts[tumor_type] += 1\n",
        "\n",
        "print(\"Распределение типов опухолей во всем датасете:\")\n",
        "for tumor_type, count in tumor_type_counts.most_common():\n",
        "    print(f\"- {tumor_type}: {count}\")\n",
        "\n",
        "total_images = len(all_files_with_type)\n",
        "print(f\"Всего изображений: {total_images}\")\n",
        "num_tumor_types = len(tumor_type_counts)\n",
        "print(f\"Количество уникальных типов опухолей: {num_tumor_types}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQE0KaIWLxAe"
      },
      "outputs": [],
      "source": [
        "types = list(tumor_type_counts.keys())\n",
        "counts = list(tumor_type_counts.values())\n",
        "\n",
        "sorted_indices = np.argsort(types)\n",
        "types = np.array(types)[sorted_indices]\n",
        "counts = np.array(counts)[sorted_indices]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(types, counts)\n",
        "plt.xlabel(\"Тип опухоли\")\n",
        "plt.ylabel(\"Количество изображений\")\n",
        "plt.title(\"Распределение типов опухолей в датасете\")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_val_data, test_data = train_test_split(\n",
        "    all_files_with_type,\n",
        "    test_size=0.15,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_val_types = [item[2] for item in train_val_data]\n",
        "type_counts_train_val = Counter(train_val_types)\n",
        "can_stratify_val = all(count > 1 for count in type_counts_train_val.values())\n",
        "\n",
        "val_size_fraction = 0.15 / 0.85\n",
        "stratify_val = train_val_types if can_stratify_val else None\n",
        "\n",
        "train_data, val_data = train_test_split(\n",
        "    train_val_data,\n",
        "    test_size=val_size_fraction,\n",
        "    random_state=42,\n",
        "    stratify=stratify_val\n",
        ")\n",
        "\n",
        "print(f\"Размер обучающей выборки: {len(train_data)}\")\n",
        "print(f\"Размер валидационной выборки: {len(val_data)}\")\n",
        "print(f\"Размер тестовой выборки: {len(test_data)}\")\n",
        "\n",
        "\n",
        "print(\"\\nРаспределение типов в обучающей выборке:\")\n",
        "print(Counter(item[2] for item in train_data))\n",
        "print(\"\\nРаспределение типов в валидационной выборке:\")\n",
        "print(Counter(item[2] for item in val_data))\n",
        "print(\"\\nРаспределение типов в тестовой выборке:\")\n",
        "print(Counter(item[2] for item in test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_segmentation_classes = 2\n",
        "foreground_class_value = 255\n",
        "background_class_value = 0\n",
        "\n",
        "print(f\"Задача сегментации: {num_segmentation_classes} класса (Фон: {background_class_value}, Клетки: {foreground_class_value}).\")\n",
        "\n",
        "total_pixels = 0\n",
        "foreground_pixels = 0\n",
        "\n",
        "print(\"\\nПодсчет баланса классов сегментации по пикселям в обучающей выборке...\")\n",
        "for _, mask_path, _ in tqdm(train_data):\n",
        "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if mask is None:\n",
        "        print(f\"Warning: Не удалось прочитать маску {mask_path}\")\n",
        "        continue\n",
        "\n",
        "    foreground_pixels += np.sum(mask == foreground_class_value)\n",
        "    total_pixels += mask.size\n",
        "\n",
        "background_pixels = 0\n",
        "if total_pixels > 0:\n",
        "    background_pixels = total_pixels - foreground_pixels\n",
        "    print(f\"Всего пикселей в обучающих масках: {total_pixels}\")\n",
        "    print(f\"Пикселей клеток: {foreground_pixels} ({foreground_pixels / total_pixels:.4f})\")\n",
        "    print(f\"Пикселей фона: {background_pixels} ({background_pixels / total_pixels:.4f})\")\n",
        "    print(f\"Соотношение фон/клетки примерно: {background_pixels/foreground_pixels:.1f} : 1\")\n",
        "else:\n",
        "    print(\"Не удалось посчитать пиксели.\")\n",
        "\n",
        "total_cells = 0\n",
        "min_cell_area = 10\n",
        "\n",
        "print(\"\\nПодсчет примерного количества клеток в обучающей выборке...\")\n",
        "for _, mask_path, _ in tqdm(train_data):\n",
        "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if mask is None:\n",
        "        continue\n",
        "\n",
        "    binary_mask = (mask == foreground_class_value).astype(np.uint8)\n",
        "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary_mask, connectivity=8)\n",
        "\n",
        "    cells_in_mask = 0\n",
        "    for i in range(1, num_labels):\n",
        "         if stats[i, cv2.CC_STAT_AREA] >= min_cell_area:\n",
        "             cells_in_mask += 1\n",
        "\n",
        "    total_cells += cells_in_mask\n",
        "\n",
        "print(f\"Примерное общее количество клеток в обучающей выборке: {total_cells}\")\n",
        "if len(train_data) > 0:\n",
        "    print(f\"Среднее количество клеток на изображение (train): {total_cells / len(train_data):.1f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Анализ на уровне изображений:\")\n",
        "print(f\"- Количество уникальных типов опухолей (по именам файлов): {num_tumor_types}\")\n",
        "print(f\"- Распределение по типам (весь датасет): см. график выше и счетчики.\")\n",
        "print(f\"- Общее количество изображений: {total_images}\")\n",
        "print(f\"- Разделение на выборки: Train={len(train_data)}, Val={len(val_data)}, Test={len(test_data)}\")\n",
        "\n",
        "print(f\"\\nАнализ для задачи сегментации (на уровне пикселей):\")\n",
        "print(f\"- Количество классов сегментации: {num_segmentation_classes} (Фон: {background_class_value}, Клетки: {foreground_class_value})\")\n",
        "if total_pixels > 0:\n",
        "    print(f\"- Баланс классов сегментации (попиксельно, train): ~{background_pixels / total_pixels:.2%} фон / {foreground_pixels / total_pixels:.2%} клетки\")\n",
        "else:\n",
        "     print(\"- Баланс классов сегментации: Не посчитан.\")\n",
        "\n",
        "if total_cells > 0:\n",
        "     print(f\"- Примерное количество объектов (клеток) в обучающей выборке: {total_cells}\")\n",
        "     print(f\"- Среднее количество клеток на изображение (train): {total_cells / len(train_data):.1f}\")\n",
        "else:\n",
        "     print(\"- Примерное количество клеток: Не посчитано.\")\n",
        "\n",
        "print(\"---------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfPKXv96hF0c"
      },
      "source": [
        "## Part 2: Unet model\n",
        "\n",
        "Implement class of Unet model according with [the original paper](https://arxiv.org/pdf/1505.04597).\n",
        "Ajust size of the network according with your input data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"CUDA доступна. Используется GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"CUDA недоступна. Используется CPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5Oa-cAFheT2"
      },
      "outputs": [],
      "source": [
        "class DoubleConv(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "class Down(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "class Up(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = Down(512, 1024 // factor)\n",
        "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
        "        self.up2 = Up(512, 256 // factor, bilinear)\n",
        "        self.up3 = Up(256, 128 // factor, bilinear)\n",
        "        self.up4 = Up(128, 64, bilinear)\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_channels = 3\n",
        "num_classes = 2\n",
        "\n",
        "model = UNet(n_channels=input_channels, n_classes=num_classes, bilinear=True)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "print(f\"Модель U-Net создана и перемещена на {device}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import albumentations as A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CancerCellDataset(Dataset):\n",
        "    def __init__(self, data_list, foreground_value=255, target_size=(512, 512)):\n",
        "        self.data_list = data_list\n",
        "        self.foreground_value = foreground_value\n",
        "        self.target_size = target_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, mask_path, _ = self.data_list[idx]\n",
        "\n",
        "        try:\n",
        "            image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "            if image is None:\n",
        "                raise IOError(f\"Не удалось загрузить изображение: {img_path}\")\n",
        "\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if mask is None:\n",
        "                raise IOError(f\"Не удалось загрузить маску: {mask_path}\")\n",
        "\n",
        "            if self.target_size:\n",
        "                image = cv2.resize(image, self.target_size, interpolation=cv2.INTER_LINEAR)\n",
        "                mask = cv2.resize(mask, self.target_size, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "            image = image.astype(np.float32) / 255.0\n",
        "            mask = (mask == self.foreground_value).astype(np.int64)\n",
        "\n",
        "            image_tensor = torch.from_numpy(image.transpose((2, 0, 1)))\n",
        "            mask_tensor = torch.from_numpy(mask)\n",
        "\n",
        "            return image_tensor, mask_tensor\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Ошибка при обработке индекса {idx}, путь к изображению: {img_path}\")\n",
        "            print(e)\n",
        "            raise e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TARGET_H, TARGET_W = 256, 256\n",
        "FG_VALUE = 255\n",
        "\n",
        "train_dataset = CancerCellDataset(train_data, foreground_value=FG_VALUE, target_size=(TARGET_H, TARGET_W))\n",
        "val_dataset = CancerCellDataset(val_data, foreground_value=FG_VALUE, target_size=(TARGET_H, TARGET_W))\n",
        "test_dataset = CancerCellDataset(test_data, foreground_value=FG_VALUE, target_size=(TARGET_H, TARGET_W))\n",
        "\n",
        "print(f\"Датасеты:\")\n",
        "print(f\"- Обучающий: {len(train_dataset)} сэмплов\")\n",
        "\n",
        "img, msk = train_dataset[0]\n",
        "print(\"\\nПример элемента из датасета:\")\n",
        "print(f\"- Тип изображения: {img.dtype}, Форма: {img.shape}\")\n",
        "print(f\"- Тип маски: {msk.dtype}, Форма: {msk.shape}\")\n",
        "assert img.shape[0] == 3, \"Изображение должно иметь 3 канала\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "import time\n",
        "import copy\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 25\n",
        "BATCH_SIZE = 3\n",
        "LEARNING_RATE = 1e-3\n",
        "NUM_WORKERS = 2\n",
        "WEIGHT_DECAY = 1e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "print(\"Пересозданы DataLoader'ы.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "print(\"Функция потерь и оптимизатор определены.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, train_loader, val_loader, device, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    history = {'train_loss': [], 'val_loss': []}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Эпоха {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        print(f\"Learning Rate: {current_lr:.1e}\")\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "                dataloader = train_loader\n",
        "            else:\n",
        "                model.eval()\n",
        "                dataloader = val_loader\n",
        "\n",
        "            running_loss = 0.0\n",
        "            processed_samples = 0\n",
        "\n",
        "            pbar = tqdm(dataloader, desc=f\"{phase.capitalize()} Эпоха {epoch+1}\")\n",
        "            for inputs, labels in pbar:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                processed_samples += inputs.size(0)\n",
        "                pbar.set_postfix({'loss': running_loss / processed_samples})\n",
        "\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloader.dataset)\n",
        "\n",
        "            print(f'{phase} Потеря: {epoch_loss:.4f}')\n",
        "\n",
        "            if phase == 'val':\n",
        "                 history['val_loss'].append(epoch_loss)\n",
        "                 if epoch_loss < best_loss:\n",
        "                    best_loss = epoch_loss\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                    print(\"Сохранена лучшая модель (по валидационной потере)\")\n",
        "            else:\n",
        "                 history['train_loss'].append(epoch_loss)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Обучение завершено за {time_elapsed // 60:.0f}м {time_elapsed % 60:.0f}с')\n",
        "    print(f'Лучшая валидационная потеря: {best_loss:4f}')\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, history\n",
        "\n",
        "try:\n",
        "    model_ft, history = train_model(\n",
        "        model,\n",
        "        criterion,\n",
        "        optimizer,\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        device,\n",
        "        num_epochs=NUM_EPOCHS\n",
        "    )\n",
        "    print(\"Обучение с аугментациями и планировщиком завершено.\")\n",
        "except NameError as e:\n",
        "     print(f\"Ошибка: Необходимая переменная не найдена ({e}). Убедись, что модель, оптимизатор, лосс и т.д. созданы.\")\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка во время обучения: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_history(history):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(history['train_loss'], label='Train Loss')\n",
        "    plt.plot(history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Эпоха')\n",
        "    plt.ylabel('Потеря (CrossEntropy)')\n",
        "    plt.title('История обучения')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "save_path = 'best_unet_model_ce_loss.pth'\n",
        "torch.save(model_ft.state_dict(), save_path)\n",
        "print(f\"модель сохронена: {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_ft.eval()\n",
        "eval_model = model_ft\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_inputs = []\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "\n",
        "print(\"Начинаем оценку на тестовой выборке...\")\n",
        "with torch.no_grad():\n",
        "    pbar = tqdm(test_loader, desc=\"Тестирование\")\n",
        "    for inputs, labels in pbar:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = eval_model(inputs)\n",
        "\n",
        "        probabilities = torch.softmax(outputs, dim=1)\n",
        "        preds = torch.argmax(probabilities, dim=1)\n",
        "\n",
        "        all_inputs.append(inputs.cpu().numpy())\n",
        "        all_preds.append(preds.cpu().numpy())\n",
        "        all_labels.append(labels.cpu().numpy())\n",
        "\n",
        "if all_inputs:\n",
        "    all_inputs = np.concatenate(all_inputs, axis=0)\n",
        "    all_preds = np.concatenate(all_preds, axis=0)\n",
        "    all_labels = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "    print(f\"Оценка завершена. Получено {len(all_preds)} предсказаний.\")\n",
        "    print(f\"Форма массива изображений: {all_inputs.shape}\")\n",
        "    print(f\"Форма массива предсказаний: {all_preds.shape}\")\n",
        "    print(f\"Форма массива истинных масок: {all_labels.shape}\")\n",
        "else:\n",
        "    print(\"Оценка не была проведена или не получено результатов.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dice_coefficient(pred, target, smooth=1e-6):\n",
        "    pred = pred.astype(bool)\n",
        "    target = target.astype(bool)\n",
        "    intersection = np.sum(pred & target)\n",
        "    return (2. * intersection + smooth) / (np.sum(pred) + np.sum(target) + smooth)\n",
        "\n",
        "def iou_score(pred, target, smooth=1e-6):\n",
        "    pred = pred.astype(bool)\n",
        "    target = target.astype(bool)\n",
        "    intersection = np.sum(pred & target)\n",
        "    union = np.sum(pred | target)\n",
        "    return (intersection + smooth) / (union + smooth)\n",
        "\n",
        "dice_scores = []\n",
        "iou_scores = []\n",
        "\n",
        "\n",
        "\n",
        "foreground_class_index = 1\n",
        "for i in range(len(all_preds)):\n",
        "    pred_mask = (all_preds[i] == foreground_class_index)\n",
        "    true_mask = (all_labels[i] == foreground_class_index)\n",
        "\n",
        "    dice = dice_coefficient(pred_mask, true_mask)\n",
        "    iou = iou_score(pred_mask, true_mask)\n",
        "\n",
        "    dice_scores.append(dice)\n",
        "    iou_scores.append(iou)\n",
        "\n",
        "avg_dice = np.mean(dice_scores)\n",
        "avg_iou = np.mean(iou_scores)\n",
        "\n",
        "print(f\"--- Метрики на тестовой выборке ---\")\n",
        "print(f\"Средний Dice Coefficient: {avg_dice:.4f}\")\n",
        "print(f\"Средний IoU (Jaccard Index): {avg_iou:.4f}\")\n",
        "print(f\"---------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "num_samples_to_show = 0\n",
        "if 'all_inputs' in locals() and len(all_inputs) > 0:\n",
        "     num_samples_to_show = min(5, len(all_inputs))\n",
        "\n",
        "if num_samples_to_show > 0:\n",
        "    print(\"\\n--- Примеры сегментации на тестовой выборке ---\")\n",
        "    plt.figure(figsize=(12, num_samples_to_show * 4))\n",
        "\n",
        "    for i in range(num_samples_to_show):\n",
        "        input_img = all_inputs[i].transpose((1, 2, 0))\n",
        "        pred_mask = all_preds[i]\n",
        "        true_mask = all_labels[i]\n",
        "\n",
        "        plt.subplot(num_samples_to_show, 3, i * 3 + 1)\n",
        "        plt.imshow(input_img)\n",
        "        plt.title(f\"Input Image #{i+1}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(num_samples_to_show, 3, i * 3 + 2)\n",
        "        plt.imshow(pred_mask, cmap='gray')\n",
        "        dice_val = dice_scores[i] if i < len(dice_scores) else float('nan')\n",
        "        iou_val = iou_scores[i] if i < len(iou_scores) else float('nan')\n",
        "        plt.title(f\"Predicted Mask #{i+1}\\nDice: {dice_val:.3f}, IoU: {iou_val:.3f}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(num_samples_to_show, 3, i * 3 + 3)\n",
        "        plt.imshow(true_mask, cmap='gray')\n",
        "        plt.title(f\"Ground Truth Mask #{i+1}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Нет данных для визуализации.\")\n",
        "\n",
        "\n",
        "\n",
        "del all_inputs, all_preds, all_labels, dice_scores, iou_scores\n",
        "del pred_mask, true_mask, input_img\n",
        "gc.collect()\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Результат:\n",
        "Модель научилась просто выдавать черную маску так как это дает хороший результат, надо попробовать другую функцию потерь в следующей части чтобы отучить ее от этого."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mgqMjFnhwZm"
      },
      "source": [
        "## Part 3: Unet training with different losses\n",
        "\n",
        "Train model in three setups:\n",
        "- Crossentropy loss\n",
        "- Dice loss\n",
        "- Composition of CE and Dice\n",
        "\n",
        "Advanced:\\\n",
        "For training procedure use one of frameworks for models training - Lightning, (Hugging Face, Catalyst, Ignite).\\\n",
        "_Hint: this will make your life easier!_\n",
        "\n",
        "Save all three trained models to disk!\n",
        "\n",
        "Use validation set to evaluate models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-6ONFwVi3n5"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, smooth=1e-6):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        probs_fg = probs[:, 1]\n",
        "        targets_fg = (targets == 1).float()\n",
        "\n",
        "        probs_flat = probs_fg.view(probs_fg.size(0), -1)\n",
        "        targets_flat = targets_fg.view(targets_fg.size(0), -1)\n",
        "\n",
        "        intersection = (probs_flat * targets_flat).sum(1)\n",
        "        pred_sum = probs_flat.sum(1)\n",
        "        target_sum = targets_flat.sum(1)\n",
        "\n",
        "        dice = (2. * intersection + self.smooth) / (pred_sum + target_sum + self.smooth)\n",
        "        return 1 - dice.mean()\n",
        "\n",
        "class CombinedLoss(nn.Module):\n",
        "    def __init__(self, weight_ce=0.5, weight_dice=0.5, dice_smooth=1e-6, ce_weight=None):\n",
        "        super(CombinedLoss, self).__init__()\n",
        "        self.ce_loss = nn.CrossEntropyLoss(weight=ce_weight)\n",
        "        self.dice_loss = DiceLoss(smooth=dice_smooth)\n",
        "        self.weight_ce = weight_ce\n",
        "        self.weight_dice = weight_dice\n",
        "        print(f\"CombinedLoss: weight_ce={weight_ce}, weight_dice={weight_dice}\")\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        ce = self.ce_loss(logits, targets)\n",
        "        dice = self.dice_loss(logits, targets)\n",
        "        loss = self.weight_ce * ce + self.weight_dice * dice\n",
        "        return loss\n",
        "\n",
        "print(\"Классы DiceLoss и CombinedLoss определены.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n--- Начинаем обучение с Dice Loss ---\")\n",
        "\n",
        "\n",
        "model_dice = UNet(n_channels=input_channels, n_classes=num_classes, bilinear=True)\n",
        "model_dice.to(device)\n",
        "\n",
        "\n",
        "optimizer_dice = optim.Adam(model_dice.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "\n",
        "criterion_dice = DiceLoss()\n",
        "\n",
        "\n",
        "try:\n",
        "    model_dice_ft, history_dice = train_model(\n",
        "        model_dice,\n",
        "        criterion_dice,\n",
        "        optimizer_dice,\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        device,\n",
        "        num_epochs=NUM_EPOCHS\n",
        "    )\n",
        "    print(\"\\n--- Обучение с Dice Loss завершено ---\")\n",
        "\n",
        "\n",
        "    save_path_dice = 'unet_dice_loss.pth'\n",
        "    torch.save(model_dice_ft.state_dict(), save_path_dice)\n",
        "    print(f\"Модель сохранена в: {save_path_dice}\")\n",
        "\n",
        "\n",
        "    plot_history(history_dice)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка во время обучения с Dice Loss: {e}\")\n",
        "\n",
        "\n",
        "del model_dice, optimizer_dice, criterion_dice\n",
        "if 'model_dice_ft' in locals(): del model_dice_ft\n",
        "if torch.cuda.is_available(): torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n--- Начинаем обучение с Combined Loss (CE + Dice) ---\")\n",
        "\n",
        "\n",
        "model_combined = UNet(n_channels=input_channels, n_classes=num_classes, bilinear=True)\n",
        "model_combined.to(device)\n",
        "\n",
        "\n",
        "optimizer_combined = optim.Adam(model_combined.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "criterion_combined = CombinedLoss(weight_ce=0.5, weight_dice=0.5)\n",
        "\n",
        "\n",
        "try:\n",
        "    model_combined_ft, history_combined = train_model(\n",
        "        model_combined,\n",
        "        criterion_combined,\n",
        "        optimizer_combined,\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        device,\n",
        "        num_epochs=NUM_EPOCHS\n",
        "    )\n",
        "    print(\"\\n--- Обучение с Combined Loss завершено ---\")\n",
        "\n",
        "\n",
        "    save_path_combined = 'unet_combined_loss.pth'\n",
        "    torch.save(model_combined_ft.state_dict(), save_path_combined)\n",
        "    print(f\"Модель сохранена в: {save_path_combined}\")\n",
        "\n",
        "\n",
        "    plot_history(history_combined)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка во время обучения с Combined Loss: {e}\")\n",
        "\n",
        "\n",
        "del model_combined, optimizer_combined, criterion_combined\n",
        "if 'model_combined_ft' in locals(): del model_combined_ft\n",
        "if torch.cuda.is_available(): torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dice_coefficient(pred, target, smooth=1e-6):\n",
        "    pred = pred.astype(bool)\n",
        "    target = target.astype(bool)\n",
        "    intersection = np.sum(pred & target)\n",
        "    return (2. * intersection + smooth) / (np.sum(pred) + np.sum(target) + smooth)\n",
        "\n",
        "def iou_score(pred, target, smooth=1e-6):\n",
        "    pred = pred.astype(bool)\n",
        "    target = target.astype(bool)\n",
        "    intersection = np.sum(pred & target)\n",
        "    union = np.sum(pred | target)\n",
        "    return (intersection + smooth) / (union + smooth)\n",
        "\n",
        "\n",
        "def evaluate_model(model_path, val_loader, device):\n",
        "    print(f\"\\nОценка модели: {model_path}\")\n",
        "\n",
        "    model = UNet(n_channels=input_channels, n_classes=num_classes, bilinear=True)\n",
        "    try:\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Ошибка: Файл {model_path} не найден!\")\n",
        "        return None, None, None, None\n",
        "    except Exception as e:\n",
        "         print(f\"Ошибка при загрузке модели {model_path}: {e}\")\n",
        "         return None, None, None, None\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    all_inputs, all_preds, all_labels = [], [], []\n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(val_loader, desc=f\"Оценка {os.path.basename(model_path)}\")\n",
        "        for inputs, labels in pbar:\n",
        "            inputs = inputs.to(device)\n",
        "            labels_cpu = labels.numpy()\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            probabilities = torch.softmax(outputs, dim=1)\n",
        "            preds = torch.argmax(probabilities, dim=1)\n",
        "\n",
        "            all_inputs.append(inputs.cpu().numpy())\n",
        "            all_preds.append(preds.cpu().numpy())\n",
        "            all_labels.append(labels_cpu)\n",
        "\n",
        "    if not all_preds:\n",
        "        print(\"Нет данных для оценки.\")\n",
        "        return None, None, None, None\n",
        "\n",
        "    all_inputs = np.concatenate(all_inputs, axis=0)\n",
        "    all_preds = np.concatenate(all_preds, axis=0)\n",
        "    all_labels = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "    dice_scores_val, iou_scores_val = [], []\n",
        "    foreground_class_index = 1\n",
        "    for i in range(len(all_preds)):\n",
        "        pred_mask = (all_preds[i] == foreground_class_index)\n",
        "        true_mask = (all_labels[i] == foreground_class_index)\n",
        "        dice = dice_coefficient(pred_mask, true_mask)\n",
        "        iou = iou_score(pred_mask, true_mask)\n",
        "        dice_scores_val.append(dice)\n",
        "        iou_scores_val.append(iou)\n",
        "\n",
        "    avg_dice = np.mean(dice_scores_val)\n",
        "    avg_iou = np.mean(iou_scores_val)\n",
        "\n",
        "    print(f\"Средний Dice на валидации: {avg_dice:.4f}\")\n",
        "    print(f\"Средний IoU на валидации: {avg_iou:.4f}\")\n",
        "\n",
        "\n",
        "    del model, inputs, labels, outputs, probabilities, preds\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "    return avg_dice, avg_iou, (all_inputs, all_preds, all_labels, dice_scores_val, iou_scores_val)\n",
        "\n",
        "\n",
        "\n",
        "model_paths = {\n",
        "    \"CE\": \"best_unet_model_ce_loss.pth\",\n",
        "    \"Dice\": \"unet_dice_loss.pth\",\n",
        "    \"Combined\": \"unet_combined_loss.pth\"\n",
        "}\n",
        "\n",
        "results = {}\n",
        "vis_data = {}\n",
        "\n",
        "\n",
        "if 'val_loader' in locals():\n",
        "    for name, path in model_paths.items():\n",
        "        if os.path.exists(path):\n",
        "             avg_dice, avg_iou, eval_results = evaluate_model(path, val_loader, device)\n",
        "             if avg_dice is not None:\n",
        "                 results[name] = {'Dice': avg_dice, 'IoU': avg_iou}\n",
        "                 vis_data[name] = eval_results\n",
        "        else:\n",
        "             print(f\"Файл для модели '{name}' ({path}) не найден, пропускаем оценку.\")\n",
        "else:\n",
        "    print(\"Ошибка: val_loader не найден. Не могу выполнить оценку.\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n--- Сводка результатов на валидационной выборке ---\")\n",
        "print(\"| Модель (Loss) | Средний Dice | Средний IoU  |\")\n",
        "print(\"|---------------|--------------|--------------|\")\n",
        "for name, metrics in results.items():\n",
        "    print(f\"| {name:<13} | {metrics['Dice']:.4f}       | {metrics['IoU']:.4f}       |\")\n",
        "print(\"----------------------------------------------------\")\n",
        "\n",
        "\n",
        "\n",
        "for model_name, eval_results in vis_data.items():\n",
        "    print(f\"\\n--- Визуализация для модели: {model_name} ---\")\n",
        "\n",
        "\n",
        "    all_inputs, all_preds, all_labels, dice_scores_val, iou_scores_val = eval_results\n",
        "\n",
        "\n",
        "    num_samples_to_show = min(5, len(all_inputs))\n",
        "\n",
        "    if num_samples_to_show == 0:\n",
        "        print(\"Нет данных для визуализации этой модели.\")\n",
        "        continue\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(12, num_samples_to_show * 4))\n",
        "\n",
        "    plt.suptitle(f\"Результаты модели: {model_name}\", fontsize=16, y=1.02)\n",
        "\n",
        "\n",
        "    for i in range(num_samples_to_show):\n",
        "        input_img = all_inputs[i].transpose((1, 2, 0))\n",
        "        pred_mask = all_preds[i]\n",
        "        true_mask = all_labels[i]\n",
        "\n",
        "\n",
        "        plt.subplot(num_samples_to_show, 3, i * 3 + 1)\n",
        "        plt.imshow(input_img)\n",
        "        plt.title(f\"Input Image #{i+1}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "\n",
        "        plt.subplot(num_samples_to_show, 3, i * 3 + 2)\n",
        "        plt.imshow(pred_mask, cmap='gray')\n",
        "        dice_val = dice_scores_val[i] if i < len(dice_scores_val) else float('nan')\n",
        "        iou_val = iou_scores_val[i] if i < len(iou_scores_val) else float('nan')\n",
        "\n",
        "        plt.title(f\"Predicted Mask ({model_name})\\nDice: {dice_val:.3f}, IoU: {iou_val:.3f}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "\n",
        "        plt.subplot(num_samples_to_show, 3, i * 3 + 3)\n",
        "        plt.imshow(true_mask, cmap='gray')\n",
        "        plt.title(f\"Ground Truth Mask #{i+1}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.98])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "del results, vis_data\n",
        "gc.collect()\n",
        "if torch.cuda.is_available(): torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQYw6g-xi5Jb"
      },
      "source": [
        "## Part 3.1: Losses conclusion\n",
        "\n",
        "Analyse results of the three models above using metrics, losses and visualizations you know (all three parts are required).\n",
        "\n",
        "Make motivated conclusion on which setup is better. Provide your arguments.\n",
        "\n",
        "Calculate loss and metrics of the best model on test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Результаты\n",
        "Ну с новыми функциями потерь дело явно бодрее идет, но модель если тренить много эпох из-за маленького разнобрая (40 семплов) капец перееобучается и трейн начинает пытаться учить\n",
        "НО лучше всего себя Dice показывает"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8s8q4objkQ7S"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lv8Fr7xzkTH2"
      },
      "source": [
        "## Part 4: Augmentations and advanced model\n",
        "\n",
        "Choose set of augmentations relevant for this case (at least 5 of them) using [Albumentations library](https://albumentations.ai/).\n",
        "Apply them to dataset (of course dynamicaly during reading from disk).\n",
        "\n",
        "One more thing to improve is model: use [PSPnet](https://arxiv.org/pdf/1612.01105v2) (either use library [implementation](https://smp.readthedocs.io/en/latest/models.html#pspnet) or implement yourself) as improved version of Unet.\n",
        "\n",
        "Alternatively you may use model of your choice (it should be more advanced than Unet ofc).\n",
        "\n",
        "Train Unet and second model on augmented data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sZ45Y3qmVtH"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "\n",
        "class CancerCellDatasetAug(Dataset):\n",
        "    def __init__(self, data_list, foreground_value=255, target_size=(512, 512), transform=None):\n",
        "        self.data_list = data_list\n",
        "        self.foreground_value = foreground_value\n",
        "        self.target_size = target_size\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, mask_path, _ = self.data_list[idx]\n",
        "\n",
        "        try:\n",
        "            image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            if image is None: raise IOError(f\"Не удалось загрузить изображение: {img_path}\")\n",
        "            if mask is None: raise IOError(f\"Не удалось загрузить маску: {mask_path}\")\n",
        "\n",
        "            if self.target_size:\n",
        "                image = cv2.resize(image, self.target_size, interpolation=cv2.INTER_LINEAR)\n",
        "                mask = cv2.resize(mask, self.target_size, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "\n",
        "            mask = (mask == self.foreground_value).astype(np.uint8)\n",
        "\n",
        "            if self.transform:\n",
        "                augmented = self.transform(image=image, mask=mask)\n",
        "                image = augmented['image']\n",
        "                mask = augmented['mask']\n",
        "\n",
        "\n",
        "            image = image.astype(np.float32) / 255.0\n",
        "\n",
        "\n",
        "            image_tensor = torch.from_numpy(image.transpose((2, 0, 1)))\n",
        "            mask_tensor = torch.from_numpy(mask).long()\n",
        "\n",
        "            return image_tensor, mask_tensor\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Ошибка при обработке индекса {idx}, путь к изображению: {img_path}\")\n",
        "            print(e)\n",
        "            raise e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.RandomRotate90(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.06, scale_limit=0.1, rotate_limit=15, p=0.7,\n",
        "                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0),\n",
        "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.6),\n",
        "    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.6),\n",
        "])\n",
        "\n",
        "\n",
        "val_test_transform = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset_aug = CancerCellDatasetAug(train_data, foreground_value=FG_VALUE, target_size=(TARGET_H, TARGET_W), transform=train_transform)\n",
        "val_dataset_aug = CancerCellDatasetAug(val_data, foreground_value=FG_VALUE, target_size=(TARGET_H, TARGET_W), transform=val_test_transform)\n",
        "test_dataset_aug = CancerCellDatasetAug(test_data, foreground_value=FG_VALUE, target_size=(TARGET_H, TARGET_W), transform=val_test_transform)\n",
        "\n",
        "print(f\"Созданы датасеты (train с аугментацией, размер {TARGET_H}x{TARGET_W}):\")\n",
        "print(f\"- Обучающий: {len(train_dataset_aug)} сэмплов\")\n",
        "print(f\"- Валидационный: {len(val_dataset_aug)} сэмплов\")\n",
        "print(f\"- Тестовый: {len(test_dataset_aug)} сэмплов\")\n",
        "\n",
        "train_loader_aug = DataLoader(train_dataset_aug, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "val_loader_aug = DataLoader(val_dataset_aug, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "test_loader_aug = DataLoader(test_dataset_aug, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "print(\"Созданы DataLoader'ы.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "model_dice_aug = UNet(n_channels=input_channels, n_classes=num_classes, bilinear=True)\n",
        "model_dice_aug.to(device)\n",
        "\n",
        "criterion_dice_aug = DiceLoss()\n",
        "print(\"Используется Dice Loss.\")\n",
        "\n",
        "optimizer_dice_aug = optim.Adam(model_dice_aug.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "print(\"Создан оптимизатор Adam.\")\n",
        "\n",
        "scheduler_dice_aug = lr_scheduler.ReduceLROnPlateau(optimizer_dice_aug, mode='min', factor=0.1, patience=10, verbose=True)\n",
        "print(\"Создан планировщик ReduceLROnPlateau.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    model_dice_aug_ft, history_dice_aug = train_model(\n",
        "        model_dice_aug,\n",
        "        criterion_dice_aug,\n",
        "        optimizer_dice_aug,\n",
        "        train_loader_aug,\n",
        "        val_loader_aug,\n",
        "        device,\n",
        "        num_epochs=NUM_EPOCHS\n",
        "    )\n",
        "    print(\"\\n--- Обучение с Dice Loss и Аугментациями завершено ---\")\n",
        "\n",
        "\n",
        "    save_path_dice_aug = 'unet_dice_augmented.pth'\n",
        "    torch.save(model_dice_aug_ft.state_dict(), save_path_dice_aug)\n",
        "    print(f\"Модель сохранена в: {save_path_dice_aug}\")\n",
        "\n",
        "\n",
        "\n",
        "    plot_history(history_dice_aug)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка во время обучения: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n--- Оценка модели (Dice + Augmentation)---\")\n",
        "\n",
        "\n",
        "eval_model = model_dice_aug_ft\n",
        "eval_model.eval()\n",
        "test_inputs, test_preds, test_labels = [], [], []\n",
        "with torch.no_grad():\n",
        "    pbar = tqdm(test_loader_aug, desc=\"Тестирование (Dice + Aug)\")\n",
        "    for inputs, labels in pbar:\n",
        "        inputs = inputs.to(device)\n",
        "        labels_cpu = labels.numpy()\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = eval_model(inputs)\n",
        "        probabilities = torch.softmax(outputs, dim=1)\n",
        "        preds = torch.argmax(probabilities, dim=1)\n",
        "\n",
        "        test_inputs.append(inputs.cpu().numpy())\n",
        "        test_preds.append(preds.cpu().numpy())\n",
        "        test_labels.append(labels_cpu)\n",
        "\n",
        "test_inputs = np.concatenate(test_inputs, axis=0)\n",
        "test_preds = np.concatenate(test_preds, axis=0)\n",
        "test_labels = np.concatenate(test_labels, axis=0)\n",
        "\n",
        "dice_scores_test, iou_scores_test = [], []\n",
        "foreground_class_index = 1\n",
        "for i in range(len(test_preds)):\n",
        "    pred_mask = (test_preds[i] == foreground_class_index)\n",
        "    true_mask = (test_labels[i] == foreground_class_index)\n",
        "    dice = dice_coefficient(pred_mask, true_mask)\n",
        "    iou = iou_score(pred_mask, true_mask)\n",
        "    dice_scores_test.append(dice)\n",
        "    iou_scores_test.append(iou)\n",
        "\n",
        "avg_dice_test = np.mean(dice_scores_test)\n",
        "avg_iou_test = np.mean(iou_scores_test)\n",
        "\n",
        "print(f\"\\n--- Метрики (Dice + Augmentation) ---\")\n",
        "print(f\"Средний Dice Coefficient: {avg_dice_test:.4f}\")\n",
        "print(f\"Средний IoU (Jaccard Index): {avg_iou_test:.4f}\")\n",
        "print(f\"-------------------------------------------------------\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Примеры сегментации (Dice + Augmentation) ---\")\n",
        "num_samples_to_show = min(5, len(test_inputs))\n",
        "if num_samples_to_show > 0:\n",
        "    plt.figure(figsize=(12, num_samples_to_show * 4))\n",
        "    for i in range(num_samples_to_show):\n",
        "        input_img = test_inputs[i].transpose((1, 2, 0))\n",
        "        pred_mask = test_preds[i]\n",
        "        true_mask = test_labels[i]\n",
        "\n",
        "        plt.subplot(num_samples_to_show, 3, i * 3 + 1)\n",
        "        plt.imshow(input_img)\n",
        "        plt.title(f\"Input Image #{i+1}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(num_samples_to_show, 3, i * 3 + 2)\n",
        "        plt.imshow(pred_mask, cmap='gray')\n",
        "        dice_val = dice_scores_test[i] if i < len(dice_scores_test) else float('nan')\n",
        "        iou_val = iou_scores_test[i] if i < len(iou_scores_test) else float('nan')\n",
        "        plt.title(f\"Predicted Mask (Dice+Aug)\\nDice: {dice_val:.3f}, IoU: {iou_val:.3f}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(num_samples_to_show, 3, i * 3 + 3)\n",
        "        plt.imshow(true_mask, cmap='gray')\n",
        "        plt.title(f\"Ground Truth Mask #{i+1}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Нет данных для визуализации.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O11pAJ6bmXZ5"
      },
      "source": [
        "## Part 4.2: Augmentations and advanced model conclusion\n",
        "\n",
        "Compare three setups:\n",
        "- Unet without augmentations (with best loss)\n",
        "- Unet with augmentations\n",
        "- Advanced model with augmentations\n",
        "\n",
        "_Hint: with augs and more complex model you may want to have more iterations._\n",
        "\n",
        "Save all three trained models to disk!\n",
        "\n",
        "Once again provide comprehensive arguments and your insights.\n",
        "\n",
        "Wich setup is better?\n",
        "\n",
        "Compute losses and metrics on test set. Measure improvement over first test evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20lpTa8vnwvd"
      },
      "outputs": [],
      "source": [
        "# # Импорт модулей\n",
        "# import segmentation_models_pytorch as smp\n",
        "# import torch\n",
        "# import albumentations as A\n",
        "# from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "# # Аугментации (без нормализации под ImageNet)\n",
        "# advanced_augmentations = A.Compose([\n",
        "#     A.HorizontalFlip(p=0.5),\n",
        "#     A.VerticalFlip(p=0.5),\n",
        "#     A.RandomRotate90(p=0.5),\n",
        "#     A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=30, p=0.8,\n",
        "#                        border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0),\n",
        "#     A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.7),\n",
        "#     A.HueSaturationValue(hue_shift_limit=30, sat_shift_limit=40, val_shift_limit=30, p=0.7),\n",
        "#     A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n",
        "#     A.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.3),\n",
        "#     ToTensorV2()\n",
        "# ])\n",
        "\n",
        "# # Создание датасетов\n",
        "# train_dataset_psp = CancerCellDatasetAug(\n",
        "#     train_data, \n",
        "#     foreground_value=FG_VALUE, \n",
        "#     target_size=(TARGET_H, TARGET_W), \n",
        "#     transform=advanced_augmentations\n",
        "# )\n",
        "\n",
        "# # Инициализация PSPNet со случайными весами\n",
        "# psp_model = smp.PSPNet(\n",
        "#     encoder_name=\"resnet18\",        # Базовая архитектура\n",
        "#     encoder_weights=None,           # Веса НЕ загружаем!\n",
        "#     in_channels=3,                  \n",
        "#     classes=num_classes,            \n",
        "#     activation=\"softmax2d\",         \n",
        "#     psp_out_channels=256,           # Уменьшено для экономии памяти\n",
        "#     psp_use_batchnorm=True,         \n",
        "#     psp_dropout=0.1                 \n",
        "# ).to(device)\n",
        "\n",
        "# # Функция потерь (Dice + CE)\n",
        "# class HybridLoss(nn.Module):\n",
        "#     def __init__(self, alpha=0.5):\n",
        "#         super().__init__()\n",
        "#         self.ce = nn.CrossEntropyLoss()\n",
        "#         self.dice = smp.losses.DiceLoss(mode=\"multiclass\")\n",
        "#         self.alpha = alpha\n",
        "\n",
        "#     def forward(self, pred, target):\n",
        "#         return self.alpha * self.ce(pred, target) + (1 - self.alpha) * self.dice(pred, target)\n",
        "\n",
        "# # Оптимизатор (одинаковый lr для всех слоев)\n",
        "# optimizer = torch.optim.AdamW(psp_model.parameters(), lr=1e-3)\n",
        "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
        "\n",
        "# # Обучение (используйте вашу функцию train_model или аналогичную)\n",
        "# # Обучение модели с распаковкой результатов\n",
        "# psp_model, history_psp = train_model(\n",
        "#     psp_model,\n",
        "#     HybridLoss(alpha=0.5),\n",
        "#     optimizer,\n",
        "#     train_loader_aug,\n",
        "#     val_loader_aug,\n",
        "#     device,\n",
        "#     num_epochs=30\n",
        "# )\n",
        "\n",
        "# # Визуализация истории обучения\n",
        "# plot_history(history_psp)\n",
        "\n",
        "# # Сохранение модели\n",
        "# torch.save(psp_model.state_dict(), \"pspnet_custom.pth\")\n",
        "# print(\"Модель успешно сохранена!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import segmentation_models_pytorch as smp\n",
        "import torch\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from scipy.ndimage import distance_transform_edt\n",
        "\n",
        "# Функция оценки метрик\n",
        "def evaluate_model_metrics(model, loader, device):\n",
        "    model.eval()\n",
        "    dice_scores = []\n",
        "    iou_scores = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, masks in tqdm(loader, desc=\"Evaluation\"):\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)\n",
        "            \n",
        "            outputs = model(images)\n",
        "            probs = F.softmax(outputs, dim=1)\n",
        "            preds = torch.argmax(probs, dim=1)\n",
        "            \n",
        "            # Convert to numpy arrays\n",
        "            preds_np = preds.cpu().numpy()\n",
        "            masks_np = masks.cpu().numpy()\n",
        "            \n",
        "            # Calculate metrics per image\n",
        "            for i in range(preds_np.shape[0]):\n",
        "                dice = dice_coefficient(preds_np[i], masks_np[i])\n",
        "                iou = iou_score(preds_np[i], masks_np[i])\n",
        "                \n",
        "                dice_scores.append(dice)\n",
        "                iou_scores.append(iou)\n",
        "    \n",
        "    return {\n",
        "        'dice': np.mean(dice_scores),\n",
        "        'iou': np.mean(iou_scores),\n",
        "        'dice_scores': dice_scores,\n",
        "        'iou_scores': iou_scores\n",
        "    }\n",
        "\n",
        "# Функция визуализации предсказаний\n",
        "def visualize_predictions(model, dataset, device, num_samples=5):\n",
        "    model.eval()\n",
        "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
        "    \n",
        "    plt.figure(figsize=(15, 3*num_samples))\n",
        "    \n",
        "    for i, idx in enumerate(indices):\n",
        "        image, mask = dataset[idx]\n",
        "        image_tensor = image.unsqueeze(0).to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output = model(image_tensor)\n",
        "            probs = F.softmax(output, dim=1)\n",
        "            pred = torch.argmax(probs, dim=1).squeeze().cpu().numpy()\n",
        "        \n",
        "        # Denormalize image if needed\n",
        "        image = image.cpu().numpy().transpose(1, 2, 0)\n",
        "        if image.shape[2] > 3:\n",
        "            image = image[..., :3]\n",
        "        \n",
        "        plt.subplot(num_samples, 3, i*3+1)\n",
        "        plt.imshow(image)\n",
        "        plt.title(f\"Input {i+1}\")\n",
        "        plt.axis('off')\n",
        "        \n",
        "        plt.subplot(num_samples, 3, i*3+2)\n",
        "        plt.imshow(pred, cmap='gray')\n",
        "        plt.title(f\"Prediction {i+1}\")\n",
        "        plt.axis('off')\n",
        "        \n",
        "        plt.subplot(num_samples, 3, i*3+3)\n",
        "        plt.imshow(mask.numpy(), cmap='gray')\n",
        "        plt.title(f\"Ground Truth {i+1}\")\n",
        "        plt.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Модифицированная функция обучения с историей\n",
        "def train_advanced_model(model, criterion, optimizer, train_loader, val_loader, scheduler, device, num_epochs=30):\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'val_loss': [],\n",
        "        'val_dice': [],\n",
        "        'val_iou': []\n",
        "    }\n",
        "    \n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_dice = 0.0\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "        \n",
        "        # Training phase\n",
        "        model.train()\n",
        "        epoch_train_loss = 0.0\n",
        "        for inputs, masks in tqdm(train_loader, desc=f\"Train Epoch {epoch+1}\"):\n",
        "            inputs = inputs.to(device)\n",
        "            masks = masks.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, masks)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            epoch_train_loss += loss.item() * inputs.size(0)\n",
        "        \n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        epoch_val_loss = 0.0\n",
        "        dice_scores = []\n",
        "        iou_scores = []\n",
        "        with torch.no_grad():\n",
        "            for inputs, masks in tqdm(val_loader, desc=\"Validation\"):\n",
        "                inputs = inputs.to(device)\n",
        "                masks = masks.to(device)\n",
        "                \n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, masks)\n",
        "                epoch_val_loss += loss.item() * inputs.size(0)\n",
        "                \n",
        "                probs = F.softmax(outputs, dim=1)\n",
        "                preds = torch.argmax(probs, dim=1)\n",
        "                \n",
        "                # Calculate metrics\n",
        "                for i in range(preds.shape[0]):\n",
        "                    pred = preds[i].cpu().numpy()\n",
        "                    true = masks[i].cpu().numpy()\n",
        "                    dice_scores.append(dice_coefficient(pred, true))\n",
        "                    iou_scores.append(iou_score(pred, true))\n",
        "        \n",
        "        # Update history\n",
        "        train_loss = epoch_train_loss / len(train_loader.dataset)\n",
        "        val_loss = epoch_val_loss / len(val_loader.dataset)\n",
        "        val_dice = np.mean(dice_scores)\n",
        "        val_iou = np.mean(iou_scores)\n",
        "        \n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_dice'].append(val_dice)\n",
        "        history['val_iou'].append(val_iou)\n",
        "        \n",
        "        # Update scheduler\n",
        "        scheduler.step(val_loss)\n",
        "        \n",
        "        # Save best model\n",
        "        if val_dice > best_dice:\n",
        "            best_dice = val_dice\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            torch.save(model.state_dict(), 'best_psp_model.pth')\n",
        "            print(f'New best model saved with Dice: {best_dice:.4f}')\n",
        "        \n",
        "        # Print epoch stats\n",
        "        print(f'Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n",
        "        print(f'Val Dice: {val_dice:.4f} | Val IoU: {val_iou:.4f}\\n')\n",
        "    \n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, history\n",
        "\n",
        "# Улучшенные аугментации\n",
        "advanced_augmentations = A.Compose([\n",
        "    # A.HorizontalFlip(p=0.5),\n",
        "    # A.ElasticTransform(alpha=120, sigma=120*0.05, alpha_affine=120*0.03, p=0.3),\n",
        "    # A.RandomGamma(gamma_limit=(70, 130), p=0.5),\n",
        "    # A.GaussianBlur(blur_limit=(3, 7), p=0.3),\n",
        "    # A.MaskDropout(max_objects=5, mask_fill_value=0, p=0.5),  # Случайное удаление областей\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.RandomRotate90(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=30, p=0.8,\n",
        "                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0),\n",
        "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.7),\n",
        "    A.HueSaturationValue(hue_shift_limit=30, sat_shift_limit=40, val_shift_limit=30, p=0.7),\n",
        "    A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n",
        "    A.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.3),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# Создание датасетов с улучшенными аугментациями\n",
        "train_dataset_psp = CancerCellDatasetAug(\n",
        "    train_data, \n",
        "    foreground_value=FG_VALUE, \n",
        "    target_size=(TARGET_H, TARGET_W), \n",
        "    transform=advanced_augmentations\n",
        ")\n",
        "\n",
        "# Инициализация PSPNet с предобученным энкодером\n",
        "psp_model = smp.PSPNet(\n",
        "    encoder_name=\"resnet50\",        # Используем предобученный ResNet-50\n",
        "    encoder_weights=\"imagenet\",     # Веса от ImageNet\n",
        "    in_channels=3,                  # RGB изображения\n",
        "    classes=num_classes,            # Классы сегментации\n",
        "    activation=\"softmax2d\",         # Активация для многоклассовой сегментации\n",
        "    psp_out_channels=512,           # Размерность выхода PSP модуля\n",
        "    psp_use_batchnorm=True,         # Использовать BatchNorm\n",
        "    psp_dropout=0.2                 # Регуляризация\n",
        ").to(device)\n",
        "\n",
        "# psp_model = smp.PSPNet(\n",
        "#     encoder_name=\"resnet34\",\n",
        "#     encoder_weights=\"imagenet\",\n",
        "#     in_channels=3,\n",
        "#     classes=num_classes,\n",
        "#     activation=\"softmax2d\",\n",
        "#     psp_use_attention=True,\n",
        "#     psp_dropout=0.5,\n",
        "#     decoder_attention_type=\"scse\"\n",
        "# ).to(device)\n",
        "\n",
        "# Комбинированная функция потерь\n",
        "class HybridLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.7):\n",
        "        super().__init__()\n",
        "        self.ce = nn.CrossEntropyLoss()\n",
        "        self.dice = smp.losses.DiceLoss(mode=\"multiclass\")\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        return self.alpha * self.ce(pred, target) + (1 - self.alpha) * self.dice(pred, target)\n",
        "\n",
        "# class BoundaryLoss(nn.Module):\n",
        "#     def __init__(self, epsilon=1e-5):\n",
        "#         super().__init__()\n",
        "#         self.epsilon = epsilon\n",
        "\n",
        "#     def _one_hot(self, mask, num_classes):\n",
        "#         return F.one_hot(mask.long(), num_classes).permute(0, 3, 1, 2).float()\n",
        "\n",
        "#     def _compute_distance_map(self, mask):\n",
        "#         mask_np = mask.cpu().numpy().astype(bool)\n",
        "#         distance_map = np.zeros_like(mask_np, dtype=np.float32)\n",
        "        \n",
        "#         for b in range(mask_np.shape[0]):\n",
        "#             for c in range(mask_np.shape[1]):\n",
        "#                 pos_mask = mask_np[b, c].astype(bool)\n",
        "#                 if pos_mask.any():\n",
        "#                     neg_mask = ~pos_mask\n",
        "#                     pos_dist = distance_transform_edt(neg_mask)\n",
        "#                     neg_dist = distance_transform_edt(pos_mask)\n",
        "#                     distance_map[b, c] = pos_dist - neg_dist\n",
        "                \n",
        "#         return torch.from_numpy(distance_map).to(mask.device)\n",
        "\n",
        "#     def forward(self, pred, target):\n",
        "#         num_classes = pred.shape[1]\n",
        "#         target_oh = self._one_hot(target, num_classes)\n",
        "#         target_dist = self._compute_distance_map(target_oh)\n",
        "        \n",
        "#         pred_soft = F.softmax(pred, dim=1)\n",
        "#         loss = (pred_soft * target_dist).abs().mean()\n",
        "        \n",
        "#         return loss\n",
        "\n",
        "# class HybridLoss(nn.Module):\n",
        "#     def __init__(self, alpha=0.4, class_weights=[0.2, 0.8]):\n",
        "#         super().__init__()\n",
        "#         self.ce = nn.CrossEntropyLoss(\n",
        "#             weight=torch.tensor(class_weights).to(device)\n",
        "#         )\n",
        "#         self.dice = smp.losses.DiceLoss(mode=\"multiclass\", classes=[1])\n",
        "#         self.focal = smp.losses.FocalLoss(mode=\"multiclass\", gamma=2.0)\n",
        "#         self.boundary = BoundaryLoss()\n",
        "#         self.alpha = alpha\n",
        "\n",
        "#     def forward(self, pred, target):\n",
        "#         return (\n",
        "#             0.3 * self.ce(pred, target) +\n",
        "#             0.3 * self.dice(pred, target) +\n",
        "#             0.2 * self.focal(pred, target) +\n",
        "#             0.2 * self.boundary(pred, target)\n",
        "#         )\n",
        "\n",
        "# Настройка оптимизатора и планировщика\n",
        "optimizer = torch.optim.AdamW([\n",
        "    {'params': psp_model.encoder.parameters(), 'lr': 1e-4},  # Меньший lr для энкодера\n",
        "    {'params': psp_model.decoder.parameters(), 'lr': 1e-3}    # Больший lr для декодера\n",
        "])\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5, verbose=True)\n",
        "\n",
        "# # Модифицированная функция обучения\n",
        "# def train_advanced_model(model, criterion, optimizer, train_loader, val_loader, scheduler, device, num_epochs=30):\n",
        "#     best_model_wts = copy.deepcopy(model.state_dict())\n",
        "#     best_dice = 0.0\n",
        "    \n",
        "#     for epoch in range(num_epochs):\n",
        "#         print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "#         print('-' * 10)\n",
        "        \n",
        "#         # Фаза обучения\n",
        "#         model.train()\n",
        "#         running_loss = 0.0\n",
        "#         pbar = tqdm(train_loader, desc=f\"Train Epoch {epoch+1}\")\n",
        "#         for inputs, masks in pbar:\n",
        "#             inputs = inputs.to(device)\n",
        "#             masks = masks.to(device)\n",
        "            \n",
        "#             optimizer.zero_grad()\n",
        "#             outputs = model(inputs)\n",
        "#             loss = criterion(outputs, masks)\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "            \n",
        "#             running_loss += loss.item() * inputs.size(0)\n",
        "#             pbar.set_postfix({'loss': running_loss/(pbar.n+1)})\n",
        "        \n",
        "#         # Фаза валидации\n",
        "#         model.eval()\n",
        "#         val_loss = 0.0\n",
        "#         dice_scores = []\n",
        "#         with torch.no_grad():\n",
        "#             for inputs, masks in val_loader:\n",
        "#                 inputs = inputs.to(device)\n",
        "#                 masks = masks.to(device)\n",
        "                \n",
        "#                 outputs = model(inputs)\n",
        "#                 loss = criterion(outputs, masks)\n",
        "#                 val_loss += loss.item() * inputs.size(0)\n",
        "                \n",
        "#                 # Расчет Dice\n",
        "#                 probs = torch.softmax(outputs, dim=1)\n",
        "#                 preds = torch.argmax(probs, dim=1)\n",
        "#                 dice = dice_coefficient(preds.cpu().numpy(), masks.cpu().numpy())\n",
        "#                 dice_scores.extend(dice)\n",
        "        \n",
        "#         # Обновление планировщика\n",
        "#         scheduler.step(val_loss)\n",
        "        \n",
        "#         # Сохранение лучшей модели\n",
        "#         epoch_dice = np.mean(dice_scores)\n",
        "#         if epoch_dice > best_dice:\n",
        "#             best_dice = epoch_dice\n",
        "#             best_model_wts = copy.deepcopy(model.state_dict())\n",
        "#             torch.save(model.state_dict(), 'best_psp_model.pth')\n",
        "#             print(f'New best model saved with Dice: {best_dice:.4f}')\n",
        "    \n",
        "#     print(f'Best Validation Dice: {best_dice:.4f}')\n",
        "#     model.load_state_dict(best_model_wts)\n",
        "#     return model\n",
        "\n",
        "# # Запуск обучения\n",
        "# psp_model, psp_model_history = train_advanced_model(\n",
        "#     psp_model,\n",
        "#     HybridLoss(alpha=0.6),\n",
        "#     optimizer,\n",
        "#     train_loader_aug,\n",
        "#     val_loader_aug,\n",
        "#     scheduler,\n",
        "#     device,\n",
        "#     num_epochs=40\n",
        "# )\n",
        "\n",
        "# model_dice_aug = UNet(n_channels=input_channels, n_classes=num_classes, bilinear=True)\n",
        "# model_dice_aug.to(device)\n",
        "\n",
        "criterion_dice_aug = DiceLoss()\n",
        "print(\"Используется Dice Loss.\")\n",
        "\n",
        "optimizer_dice_aug = optim.Adam(psp_model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "print(\"Создан оптимизатор Adam.\")\n",
        "\n",
        "scheduler_dice_aug = lr_scheduler.ReduceLROnPlateau(optimizer_dice_aug, mode='min', factor=0.1, patience=10, verbose=True)\n",
        "print(\"Создан планировщик ReduceLROnPlateau.\")\n",
        "\n",
        "# Запуск обучения\n",
        "psp_model, psp_model_history = train_advanced_model(\n",
        "    psp_model,\n",
        "    criterion_dice_aug,\n",
        "    optimizer_dice_aug,\n",
        "    train_loader_aug,\n",
        "    val_loader_aug,\n",
        "    scheduler_dice_aug,\n",
        "    device,\n",
        "    num_epochs=40\n",
        ")\n",
        "\n",
        "# Функция для отображения истории обучения\n",
        "def plot_history(history):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    \n",
        "    # Loss plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history['train_loss'], label='Train Loss')\n",
        "    plt.plot(history['val_loss'], label='Val Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    \n",
        "    # Metrics plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history['val_dice'], label='Val Dice')\n",
        "    plt.plot(history['val_iou'], label='Val IoU')\n",
        "    plt.title('Validation Metrics')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Score')\n",
        "    plt.legend()\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Оценка на тестовых данных\n",
        "test_metrics = evaluate_model_metrics(psp_model, test_loader_aug, device)\n",
        "print(f\"Test Dice: {test_metrics['dice']:.4f}, Test IoU: {test_metrics['iou']:.4f}\")\n",
        "\n",
        "\n",
        "# Визуализация истории обучения\n",
        "plot_history(psp_model_history)\n",
        "\n",
        "# Сохранение модели\n",
        "torch.save(psp_model.state_dict(), \"pspnet_custom_adv.pth\")\n",
        "print(\"Модель успешно сохранена!\")\n",
        "\n",
        "# Визуализация результатов\n",
        "visualize_predictions(psp_model, test_dataset_aug, device, num_samples=5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv_jupyter",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
